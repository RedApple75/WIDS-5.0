{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07515638-410b-4460-bdfa-302bb12a9342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65b3fa94-3e50-4c8f-91c7-ab8973092647",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "IMG_SIZE = 224\n",
    "DATA_DIR = r'F:\\WIDS-5.0\\data\\plantvillage dataset\\color' # <--- CHANGE THIS\n",
    "\n",
    "# ImageNet statistics for normalization\n",
    "norm_mean = [0.485, 0.456, 0.406]\n",
    "norm_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std) # Critical for Transfer Learning\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16210802-610f-4335-a5ff-d7f939521b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = datasets.ImageFolder(root=DATA_DIR)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataset.dataset.transform = train_transforms\n",
    "val_dataset.dataset.transform = val_transforms\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "class_names = full_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7b0f4ad-e21a-403e-a4ae-1c1697b05543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\ruchi/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Load ResNet18 with default weights (ImageNet)\n",
    "model_tl = models.resnet18(weights='DEFAULT')\n",
    "\n",
    "# Freeze the backbone\n",
    "for param in model_tl.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final fully connected layer (fc)\n",
    "# ResNet18 input to fc is 512\n",
    "num_ftrs = model_tl.fc.in_features\n",
    "model_tl.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_tl = model_tl.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba9943f-2955-437a-b887-62fd748f9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Note: We pass the optimizer as an argument so we can switch it later\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    return running_loss / len(loader), 100 * correct / total\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    return running_loss / len(loader), 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eb2f12e-98f8-4116-b52e-d2a418cc4ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Feature Extraction Training...\n",
      "Epoch 1/5 | Train Acc: 82.82% | Val Acc: 93.39%\n",
      "Epoch 2/5 | Train Acc: 94.10% | Val Acc: 94.63%\n",
      "Epoch 3/5 | Train Acc: 95.35% | Val Acc: 95.40%\n",
      "Epoch 4/5 | Train Acc: 96.04% | Val Acc: 95.76%\n",
      "Epoch 5/5 | Train Acc: 96.48% | Val Acc: 96.24%\n"
     ]
    }
   ],
   "source": [
    "# Create optimizer only for the parameters that require gradients (the new head)\n",
    "optimizer_head = optim.Adam(filter(lambda p: p.requires_grad, model_tl.parameters()), lr=0.001)\n",
    "\n",
    "print(\"ðŸš€ Starting Feature Extraction Training...\")\n",
    "for epoch in range(5):\n",
    "    train_loss, train_acc = train_one_epoch(model_tl, train_loader, optimizer_head)\n",
    "    val_loss, val_acc = evaluate(model_tl, val_loader)\n",
    "    print(f\"Epoch {epoch+1}/5 | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92dc9698-011d-408c-9dfe-7cd4e933eb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Unfreezing backbone for Fine-Tuning...\n",
      "Fine-Tune Epoch 1/5 | Train Acc: 98.23% | Val Acc: 99.21%\n",
      "Fine-Tune Epoch 2/5 | Train Acc: 99.80% | Val Acc: 99.13%\n",
      "Fine-Tune Epoch 3/5 | Train Acc: 99.93% | Val Acc: 99.45%\n",
      "Fine-Tune Epoch 4/5 | Train Acc: 99.97% | Val Acc: 99.59%\n",
      "Fine-Tune Epoch 5/5 | Train Acc: 99.99% | Val Acc: 99.62%\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”¥ Unfreezing backbone for Fine-Tuning...\")\n",
    "\n",
    "# Unfreeze all layers\n",
    "for param in model_tl.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Use a much smaller learning rate (1e-4) to avoid destroying learned features\n",
    "optimizer_ft = optim.Adam(model_tl.parameters(), lr=1e-4)\n",
    "\n",
    "# Train for a few more epochs with the new optimizer\n",
    "for epoch in range(5):\n",
    "    train_loss, train_acc = train_one_epoch(model_tl, train_loader, optimizer_ft)\n",
    "    val_loss, val_acc = evaluate(model_tl, val_loader)\n",
    "    print(f\"Fine-Tune Epoch {epoch+1}/5 | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708818dc-d42d-4567-bf12-49c735af7114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
